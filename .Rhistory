x
names(x)
m <- matrix(1:4, nrow=2, ncol=2)
dimnames(m) <- list(c("a","b"),c("c","d"))
m
m[a,d]
m["a","d"]
read.csv("C:\Learning\Coursera\RProgramming\hw1_data.csv")
read.csv("C:/Learning/Coursera/RProgramming/hw1_data.csv")
quiz1_data <- read.csv("C:/Learning/Coursera/RProgramming/hw1_data.csv")
head(quiz1_data, 2)
tail(quiz1_data, 2)
quiz1_data$Ozone[47]
summary(quiz1_data$Ozone)
high_oz_temp <- subset(quiz1_data, Ozone>31 and Temp>90 )
high_oz_temp <- subset(quiz1_data, Ozone>31 & Temp>90)
summary(gih_oz_temp)
summary(high_oz_temp$Solar.R)
month_six <= subset(quiz1_data, Month=6)
month_six <= subset(quiz1_data, Month==6)
month_six <- subset(quiz1_data, Month==6)
summary(month_six$Temp)
month_five <- subset(quiz1_data, Month==5)
summary(month_five$Ozone)
install.packages("shiny")
fileUrl <= "https://data.baltimeorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
fileUrl <- "https://data.baltimeorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
getwd()
dir.create("coursera")
dir.create("coursera/gacd")
dir.create("coursera/gacd/data")
download.file(fileUrl, destfile="./coursera/gacd/data/cameras.csv", method="curl")
fileUrl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
cd("coursera")
dir.cd("coursera")
file.cd("coursera")
dir.move("coursera")
download.file(fileUrl, destfile="coursera/gacd/data/cameras.csv", method="curl")
download.file(fileUrl, destfile="./cameras.csv", method="curl")
getwd()
download.file(fileUrl, destfile="./cameras.csv", method="surl")
download.file(fileUrl, destfile="./cameras.csv", method="auto")
list.files("coursera/gacd/data")
download.file(fileUrl, destfile="coursera/gacd/data/cameras2.csv", method="curl")
cameraData <- read.table("coursera/gacd/data/cameras.csv", sep=",", header=TRUE)
head(cameraData)
head(cameraData)
cameraData <- read.xslx("coursera/gacd/data/cameras.xslx", sheetIndex=1, header=TRUE)
library(xslx)
library(xslx)
library("xslx")
library(XML)
install.packages("XML")
library(XML)
install.packages("xslx")
fileUrl <- "http://www.w3schools.com/xml/simple.xml"
doc <- xmlParseTree(fileUrl, useInternal=TRUE)
doc <- xml.parseTree(fileUrl, useInternal=TRUE)
doc <- xml.parsetree(fileUrl, useInternal=TRUE)
doc <- xml.xmlParseTree(fileUrl, useInternal=TRUE)
doc <- xmlParseDoc(fileUrl, useInternal=TRUE)
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
doc <- xmlTreeParse("./coursera/gacd/data/simple.xml", useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
rootNode[[1]]
rootNode[[1]][[1]]
rootNode[[1]][[2]]
rootNode[[1]][[price]]
rootNode[[1]][["price"]]
rootNode["food/price"]]
rootNode[["food/price"]]
rootNode["food/price"]
install.packages("jsonlite")
library(jsonlite)
myjson <- toJSON(quiz1_data)
cat(myjson)
quiz1_data_2 <- fromJSON(myjson)
quiz1_data_2
donwload.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", destfile="acs.csv")
download.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", destfile="acs.csv")
quiz_acs <- download.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", destfile="acs.csv")
quiz_acs <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", sep=",", destfile="acs.csv")
quiz_acs <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", destfile="acs.csv")
quiz_acs
quiz_acs <- read.csv("acs.csv")
quiz_acs
summary(quiz_acs$VAL)
count(quiz_acs$VAL == 24)
highval <- subset(quiz_acs, VAL == 24)
summary(highval)
summary(highval$VAL)
table(highval$VAL)
highval$VAL
length(highval$VAL)
quiz_acs <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx
", destfile="NGAP.xslx")
quiz_ngap <- read.csv("./cousera/gacd/NGAP_subset.csv")
quiz_ngap <- read.csv("./coursera/gacd/NGAP_subset.csv")
quiz_ngap <- read.csv("./coursera/gacd/data/NGAP_subset.csv")
sum(quiz_ngap$Zip*quiz_ngap$Ext,na.rm=T)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml", destfile="coursera/gacd/data/restaurants.xml")
doc <- xmlTreeParse("coursera/gacd/data/restaurants.xml", useInternal=TRUE)
doc
xpathSApply(doc, path="//row[zipcode=21231]", xmlValue)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", destfile="coursera/gacd/data/acs_pid.csv")
fss_pid <- read.csv("coursera/gacd/data/acs_pid.csv", header=TRUE)
library("XML", lib.loc="C:/Program Files/R/R-3.0.2/library")
xpathSApply(doc, path="//row[zipcode=21231]")
doc <- xmlTreeParse("coursera/gacd/data/restaurants.xml", useInternal=TRUE)
xpathSApply(doc, path="//row[zipcode=21231]")
DT <- fread("coursera/gacd/data/ss06pid.csv")
install.packages("data.table")
install.packages("data.table")
library("data.table", lib.loc="C:/Program Files/R/R-3.0.2/library")
DT <- fread("coursera/gacd/data/ss06pid.csv")
tables()
mean(DT$pwgtp15,by=DT$SEX)
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
tapply(DT$pwgtp15,DT$SEX,mean)
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
sapply(split(DT$pwgtp15,DT$SEX),mean)
DT[,mean(pwgtp15),by=SEX]
system.time(DT[,mean(pwgtp15),by=SEX])
head(ss_hid,3)
ss_hid <- read.csv("coursera/gacd/data/ss06hid.csv", header=TRUE)
head(ss_hid,3)
summary(ss_hid$FES)
library(DAAG)
install.packages("DAAG")
library("DAAG", lib.loc="C:/Program Files/R/R-3.0.2/library")
data(allbacks)
book_mlr = lm(weight ~ volume + cover, data = allbacks)
book_mlr
summary(book_mlr)
states = read.csv("http://bit.ly/dasi_states")
pov_slr = lm(poverty ~ female_house, data=states)
summary(pov_slr)
pov_mlr = lm(poverty ~ female_house + white, data=states)
summary(pov_mlr)
anova(pov_mlr)
cognitive = read.csv("http://bit.ly/dasi_cognitive")
cog_full = lm(kid_score ~ mom_hs + mom_iq + mom_work + mom_age, data=cognitive)
summary(cog_full)
pt(2.201, df=429, lower.tail=FALSE) * 2
qt(0.025, df=429)
cog_mid = lm(kid_score ~ mom_hs + mom_iq, data=cognitive)
summary(cog_mid)
cog_rev = lm(kid_score ~ mom_iq + mom_hs, data=cognitive)
summary(cog_rev)
cog_red1 = lm(kid_score ~ mom_iq + mom_hs + mom_work, data=cognitive)
summary(cog_red1)
cog_red2 = lm(kid_score ~ mom_iq + mom_hs, data=cognitive)
summary(cog_red2)
cog_final = lm(kid_score ~ mom_hs + mom_iq + mom_work, data=cognitive)
plot(cog_final$residuals ~ cognitive$mom_iq)
hist(cog_final$residuals)
qqnorm(cog_final$residuals)
qqline(cog_final$residuals)
plot(cog_final$residuals ~ cog_final$fitted)
plot(cog_final$residuals)
install.packages("KernSmooth")
library("KernSmooth", lib.loc="C:/Program Files/R/R-3.0.2/library")
args(lm)
formals(lm)
x # print x
x ## print x
add2 <- function(x, y) {
a + b
}
add2(2,3)
add2 <- function(x, y) {
x + y
}
add2(2,3)
above <- function(x, n) {
use = x > n  # logical vector, use_i = TRUE when x_i > 10
x[use]        # subset for those indices that are TRUE
}
above(1:15, 7)
columnmean <- function(y) {
nc <- ncol(y)
means <- numeric(nc)
for (i in 1:nc) {
means[i] = mean(y[,i])
}
means
}
columnmean(airquality)
columnmean <- function(y, removeNA = TRUE) {
nc <- ncol(y)
means <- numeric(nc)
for (i in 1:nc) {
means[i] = mean(y[,i], na.rm = removeNA)
}
means
}
columnmean(airquality)
make.power <- function(n) {
pow <- function(x) {
x^n
}
pow
}
cube <- make.power(3)
square <- make.power(2)
cube(4)
ls(environment(cube))
get("n", environment(square))
y <- 10
f <- function(x) {
y <- 2
y^2 + g(x)
}
g <- function(x) {
x * y
}
f(3)
x = 1:4; y=6:9
x + y
x > 2
x >= 2
y == 8
x * y
x / y
x = matrix(1:4,2,2)
y = matrix(rep(10,4),2,2)
x * y
x / y
x %*% y
date()
x = as.Date("1970-01-01")
unclass(x)
class(x)
y <- date()
class(y)
weekdays()
weekdays(x)
months(x)
quarters(x)
x <- Sys.time()
x
p <- as.POSIXlt(x)
names(unclass(p))
names(p)
p$sec
p$mday
p$wday
p$yday
p$hour
unclass(x)
datestring <- c("January 10,2012 10:40", "December 9,2011")
x <- strptime(datestring, "%B %d,%Y %H:%M")
x
datestring <- c("January 10,2012 10:40", "December 9, 2011 09:10")
x <- strptime(datestring, "%B %d,%Y %H:%M")
x
class(x)
x[1]$week
x[1]$wday
x[2]$wday
cube <- function(x,n) {
x^3
}
cube(3)
n
cube <- function(x,notfound) {
x^3
}
cube(3)
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
pwd
pwd()
plot(book_mlr)
plot(book_mlr)
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readLines(con)
close(con)
htmlCode
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes=T)
xpathSApply(html,"//title",xmlValue)
library(httr)
install.packages("httr")
library("httr", lib.loc="C:/Program Files/R/R-3.0.2/library")
html2 = GET(url)
content2 = content(html2, as="text")
parsedHtml=htmlParse(content2,asText=T)
parsedHtml
pg1 = GET("http://httpbin.org/basic-auth/user/passwd")
pg1
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
jtlPage <- url(url)
htmlLines = readLines(jtlPage)
length(htmlLines)
nchar(htmlLines[10])
nchar(htmlLines[c(10,20,30,40)])
nchar(htmlLines[c(10,20,30,100)])
fwf = read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
fwf = read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", widths=c(9,9,4,9,4,9,4,9,4))
fwf = read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", widths=c(9,9,4,9,4,9,4,9,4), skip=4)
fwf = read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", widths=c(9,9,4,9,4,9,4,9,4), skip=4, colClasses=c("character","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric"))
fwf = read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", widths=c(10,9,4,9,4,9,4,9,4), skip=4, colClasses=c("character","numeric","numeric","numeric","numeric","numeric","numeric","numeric","numeric"))
sum(fwf$V4)
load(url("http://www.openintro.org/stat/data/evals.RData"))
profeval <- load(url("http://www.openintro.org/stat/data/evals.RData"))
?load
load(url("http://www.openintro.org/stat/data/evals.RData"))
summary(score)
summary(evals$score)
length(evals[evals$score<3])
length(evals$score[evals$score<3])
plot(evals$score ~ evals$bty_avg)
svb = lm(score ~ bty_avg, data=evals)
plot(lm)
plot(svb)
summary(svb)
plot(svb$residuals)
plot(svb)
hist(svb$residuals)
?jitter
plot(svb$residuals)
plot(evals$score ~ evals$bty_avg)
plot(evals$score ~ jitter(evals$bty_avg))
plot(evals[, 13:19])
m_bty_gen <- lm(score ~ bty_avg + gender, data = evals);
summary(m_bty_gen)
multiLines(m_bty_gen)
m_bty_rank <- lm(score ~ bty_avg + gender, data = evals);
summary(m_bty_rank)
m_bty_rank <- lm(score ~ bty_avg + rank, data = evals);
summary(m_bty_rank)
m_full <- lm(score ~ rank + ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
summary(m_full)
summary(m_full)$adj.r.squared
m1 <- lm(score ~ rank + ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg - bty_avg, data = evals)
summary(m1)$adj.r.squared
m2 <- lm(score ~ rank + ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg - cls_profs, data = evals)
summary(m2)$adj.r.squared
m3 <- lm(score ~ rank + ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg - cls_students, data = evals)
summary(m3)$adj.r.squared
m4 <- lm(score ~ rank + ethnicity + gender + language + age + cls_perc_eval
+ cls_students + cls_level + cls_profs + cls_credits + bty_avg - rank, data = evals)
summary(m4)$adj.r.squared
summary(m2)
summary(lm(score ~ bty_avg, data=evals))
noise <- function(n,mean,sd) {}
rnorm(n,mean,sd)
noise <- function(n,mean,sd) { rnorm(n,mean,sd)}
noise(5,1,2)
noise(1:5,1:5,2)
mapply(noise,1:5,1:5,2)
mapply(noise,1:5,1:5,1:5)
mapply(noise,1:5,matrix(c(1,2,3,4,5,1,2,3,4,5),5,2))
mapply(noise,1:5,1:5,1:5)
mapply(noise,1:5,1:5,11:15)
mapply(noise,1:5,1:5,seq(1,21,by=5))
log(-1)
printmessage <- function(x) {}
printmessage <- function(x) {                                                                                                                           }
printmessage <- function(x) { if (x>0) {print("x gt zero")} else {print("x le zero")} invisible(x) }
printmessage <- function(x) {
if (x>0)
print("x gt zero")
else
print("x le zero")
invisible(x)
}
printmessage(1)
printmessage(-1)
printmessage(0)
printmessage(NA)
printmessage2 <- function(x) {
if (is.na(x))
print("x is a missing value")
else if (x>0)
print("x gt zero")
else
print("x le zero")
invisible(x)
}
x <- log(-1)
printmessage2(x)
printmessage2(1/0)
printmessage2(0/0)
printmessage2(log(-1))
printmessage(NA)
traceback()
traceback(printmessage(NA))
debug("printmessage")
printmessage(NA)
printmessage(NA)
printmessage(NA)
debug("printmessage")
printmessage(NA)
undebug("printmessage")
printmessage(NA)
mean(x)
mean(y)
traceback()
lm(y ~ x)
traceback()
debug(lm)
lm(y ~x)
options(error=recover)
read.csv("nix")
options(error=NULL)
library(datasets)
data(iris)
?iris
head(iris, 10)
complete.cases(iris)
iris[,{mean(Sepal.length)},by=Species]
lapply(X=iris$Sepal.Length,FUN=mean(),by=iris$Species)
lapply(X=iris,FUN=mean(Sepal.Length),by=iris$Species)
lapply(X=iris$Sepal.Length,FUN=mean,by=iris$Species)
lapply(X=iris$Sepal.Length,FUN=mean)
mean(iris$Sepal.Length[Species="virginica",])
mean(iris$Sepal.Length[,Species="virginica"])
mean(subset(iris,"Sepal.Length",Species=="virginica")
e
subset(iris,$Species=="virginica")
subset(iris,Species=="virginica")
mean(subset(iris,Species=="virginica")$Sepal.Length)
apply(iris[, 1:4], 2, mean)
apply(iris[, 1:4], 1, mean)
apply(iris, 2, mean)
rowMeans(iris[, 1:4])
data(mtcars)
mean(mtcars$mpg, mtcars$cyl)
with(mtcars, tapply(mpg, cyl, mean))
with(mtcars, tapply(mpg, cyl, sd))
with(mtcars, tapply(mpg, cyl, mean))
split(mtcars, mtcars$cyl)
with(mtcars, tapply(mpg, cyl, mean))
26.66364 - 15.10000
with(mtcars, tapply(mpg, cyl, mean))
with(mtcars, tapply(mpg, cyl, mean, na.action=na.omit))
with(mtcars, tapply(hp, cyl, mean, na.action=na.omit))
209.21429 - 82.63636
with(iris, tapply(Sepal.Length, Species, mean))
tapply(iris$Sepal.Length, iris$Species, mean)
apply(iris[, 1:4], 2, mean)
str(pg1)
str(str)
str(lm)
str(airquality)
str(split(airquality,airquality$Month))
x = rnorm(10,20,2)
x
summary(x)
str(x)
str(x,digits.d=3)
str(x,digits.d=5)
str(x,digits=3)
set.seed(1)
rnorm(5)
rnorm(5)
set.seed(1)
rnorm(5)
rpois(10,1)
set.seed(1)
rpois(10,1)
set.seed(1)
rnorm(5)
rpois(10,1)
set.seed(1)
rnorm(5)
rnorm(5)
rpois(10,1)
set.seed(1)
rpois(10,1)
set.seed(20)
x <- rnorm(100)
e <- rnorm(100,0,2)
y <- 0.5 + 2*x + e
summary(y)
plot(x,y)
plot(y ~ x)
plot(x ~ y)
plot(y ~ x)
set.seed(10)
x = rbinom(100,1,0.5)
e <- rnorm(100,0,2)
y <- 0.5 + 2*x + e
summary(y)
plot(y ~ x)
set.seed(1)
x <- rnorm(100)
log.mu <- 0.5 + 0.3*x
y <- rpois(100, exp(log.mu))
summary(y)
plot(y ~ x)
set.seed(1)
sample(1:10,4)
sample(1:10,4)
sample(letters,5)
sample(1:10)
sample(1:10)
sample(1:10, replace=T)
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript3.R")
setwd("./GitHub//ExData_Plotting1")
source("plot1.R")
source("plot2.R")
source("plot3.R")
source("plot4.R")
